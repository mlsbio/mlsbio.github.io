[
    {
        "id": 6,
        "title": "Exploring simulators for particle picking in cryo-electron tomography",
        "authors": "Serena Arghittu, Lars Dingeldein, Geoffrey Woollard, Lingli Kong, Magnus Petersen, Sonya Hanson, Roberto Covino, Pilar Cossio",
        "abstract": "To understand how proteins function, we need to know the conformations that they adopt and with what they interact in their native cellular environment. Cryo-electron tomography (cryo-ET) offers a powerful tool by enabling \\textit{in situ} imaging of proteins. But high noise levels and the need for expertise in particle identification limit its scalability. In this study, we present a machine learning framework for automated recognition and localization of particles in cryo-ET data. We treat particle picking as an object recognition task and employ a U-Net-based architecture for multi-class segmentation. To overcome the scarcity of annotated data, we train our model on synthetic tomograms generated by a simulator that incorporates empirical noise from publicly available cryo-ET datasets. Our results show that training on a mixed dataset containing both synthetic and empirical backgrounds provides the most effective particle-picking performance, enhancing the model\u2019s robustness to different background types. Furthermore, we demonstrate that training exclusively on simulated particles enables the model to reliably distinguish particles from background in real tomograms, highlighting the potential of simulation-based training strategies in cryo-ET.",
        "category": "Poster",
        "location": " San Diego"
    },
    {
	    "id": 66,
	    "title":"Leveraging in Silico Predictors for Antibody Design via Multi-Objective Bayesian Optimization",
	    "authors":"Jackie Rao,Ferran Gonzalez,Leon Gerard, Alexandra Gessner",
	     "abstract":"Antibody lead optimization is inherently a multi-objective challenge in drug discovery. Achieving a balance between different drug-like properties is crucial for the development of viable candidates, and this search becomes exponentially challenging as desired properties grow. The ever-growing zoo of sophisticated in silico tools for predicting antibody properties calls for an efficient joint optimization procedure to overcome resource-intensive sequential filtering pipelines. We present BOAT, a versatile Bayesian optimization framework for multi-property antibody engineering. Our 'plug-and-play' framework couples uncertainty-aware surrogate modeling with a genetic algorithm to jointly optimize various predicted antibody traits while enabling efficient exploration of sequence space. Through systematic benchmarking against genetic algorithms, we demonstrate that our method efficiently explores the Pareto front where the combinatorial ground truth is available.",
	    "category":"Poster",
	    "location":"Copenhagen"

    },
    {
	    "id": 117,
	    "title":"Self Distillation Fine-Tuning of Protein Language Models Improves Versatility in Protein Design",
	    "authors":"Amin Tavakoli, Raswanth Murugan, Ozan Gokdemir, Arvind Ramanathan, Frances Arnold, Anima Anandkumar",
	     "abstract":"Supervised fine-tuning (SFT) is a standard approach for adapting large language models to specialized domains, yet its application to protein sequence modeling and protein language models (PLMs) remains ad hoc. This is in part because high-quality annotated data are far more difficult to obtain for proteins than for natural language. We present a simple and general recipe for fast SFT of PLMs, designed to improve the fidelity, reliability, and novelty of generated protein sequences. <br/>Unlike existing approaches that require costly precompiled experimental datasets for SFT, our method leverages the PLM itself, integrating a lightweight curation pipeline with domain-specific filters to construct high-quality training data. These filters can independently refine a PLMâ€™s output and identify candidates for in vitro evaluation; when combined with SFT, they enable PLMs to generate more stable and functional enzymes, while expanding exploration into protein sequence space beyond natural variants.<br/>Although our approach is agnostic to both the choice of protein language model (PLM) and the protein system, we demonstrate its effectiveness with a genome-scale PLM (GenSLM) applied to the tryptophan synthase enzyme family. The supervised fine-tuned model generates sequences that are not only more novel but also display improved characteristics across both targeted design constraints and emergent protein property measures.",
	    "category":"Poster",
	    "location":"Copenhagen"

    }, 
    {
        "id": 8,
        "title": "REPTRA: Mapping Immune T Cell Receptor Activity from Full Sequences with a Debiased Contrastive Loss",
        "authors": "John Abel, Brinda Vijaykumar, Neel Patel, Anthony Coyle, Christophe Benoist, Daniel Pregibon",
        "abstract": "Contrastive learning is amenable to representing the vast space of interaction between highly specific T cell receptors (TCRs) and the epitopes to which they bind, potentially enabling diverse applications in immune engineering. However, progress in mapping TCR-epitope recognition has been limited by skewed datasets and training approaches that may exacerbate biases and obfuscate model performance. Furthermore, most TCR-epitope models represent only one of three complementarity-determining regions (CDRs) of the TCR, potentially limiting performance. Here, we present a CLIP-style contrastive-learning model for representation of epitopes and T cell receptor activity (REPTRA), incorporating a full TCR sequence representation and trained using a debiased InfoNCE loss. We demonstrate resulting improvements in performance, and perform ablations to identify the contributions of the modified loss and TCR representation. Furthermore, we apply an interpretability analysis to the REPTRA attention-pooling projection heads to reveal that CDR1 and CDR2, in addition to CDR3, are important for learning TCR-epitope recognition. In doing so, we develop a performant model for contrastive mapping of T cell receptor activity.",
        "category": "Poster",
        "location": " San Diego"
    },
    {
        "id": 20,
        "title": "Reciprocal Best Matching: a new pipeline for scoring models with unknown stoichiometry in CASP experiments",
        "authors": "Rongqing Yuan, Jing Zhang, Qian Cong",
        "abstract": "Accurate prediction of protein complex structures remains a significant challenge, particularly when stoichiometry information is unavailable. In the recent Critical Assessment of Structure Prediction Round XVI (CASP16), the \u201cPhase 0\u201d challenge was introduced to stimulate progress in this area. However, existing evaluation tools, such as OpenStructure, introduce systematic biases when evaluating models with stoichiometries different from the target, sometimes favoring those with excess subunits and inflating scores for incorrect stoichiometries. To address this issue, we developed the Reciprocal Best Matching (RBM) pipeline. RBM compares predicted and target structures by bidirectionally matching interfaces and assigning penalizations to unmatched interfaces. This approach penalizes incorrect stoichiometries in a consistent and unbiased manner while preserving strong correlation with established CASP metrics. Application of RBM in CASP16 assessments revealed improved discrimination between correctly and incorrectly stoichiometric models. We also provide a standalone software for our RBM pipeline, which is useful for protein complex structure prediction evaluation and future CASP experiments.",
        "category": "Poster",
        "location": " San Diego"
    },
    {
        "id": 21,
        "title": "AbTune: layer-wise selective Fine-Tuning of protein language models for Antibodies",
        "authors": "Xiaotong Xu",
        "abstract": "Antibodies play crucial roles in immune defense and serve as key therapeutic agents for numerous diseases. The structural and sequence diversity of their antigen recognition loops, coupled with the scarcity of high-quality data, pose significant challenges in the development of generalizable predictive models. Here, we present a sequence specific fine-tuning strategy for antibodies that partially bypass the need for generalization. We evaluated this approach in three biologically relevant tasks: antibody structure prediction, zero-shot prediction of beneficial mutation in antibody-antigen complexes and binding affinity prediction. In all three tasks, we observed substantial improvements over pLM baselines without fine-tuning, while using only a fraction of the computational and time resources required for fully fine-tuning antibody-specific pLMs. We further extended our method to layer-wise selective fine-tuning, with the aim of investigating how model size, fine-tuning duration, and fine-tuning depth collectively influence downstream performance. Fine-tuning 50%-75% of LoRA layers was found to be optimal for small- to medium-sized pLMs, with the initial perplexity of each sequence providing some guidance for determining the best fine-tuning duration. Building on these insights, our approach achieves state-of-the-art performance in predicting beneficial mutations and binding affinity. These results establish our layer-wise selective, sequence specific fine-tuning strategy as an efficient and practical strategy for antibody-related prediction tasks, providing a useful protocol for future applications in immunology.",
        "category": "Contributed talk",
        "location": " Copenhagen"
    },
    {
        "id": 22,
        "title": "Adapting Co-Folding Models for Structure-Based Protein-Protein Docking Through Flow Matching",
        "authors": "Da Xu, Lee-Shin Chu, Jeffrey Gray",
        "abstract": "Co-folding models like AlphaFold have revolutionized protein complex structure prediction, yet their reliance on multiple sequence alignments (MSAs) limits their applicability on challenging targets such as antibody-antigen complexes. An alternative approach, structure-based protein-protein docking, predicts the complex structure from the unbound monomer structures without requiring MSAs. In this work, we propose a novel method to adapt co-folding models for structure-based docking by replacing their template module with a docking module, followed by training end-to-end with a flow-matching objective. We apply our method to AlphaFold-Multimer (AF-M) using the OpenFold implementation and transform it into a generative docking model, which we name AF2Dock. We evaluate AF2Dock on the PINDER-AF2 benchmark and an antibody/nanobody test set, and demonstrate that AF2Dock consistently performs competitively or outperforms other structure-based docking methods when using non-holo inputs, especially in the case of antibody and nanobody complexes. Although AF2Dock underperforms co-folding AF-M and AF3 in success rates when using non-holo inputs, it produces orthogonal predictions and successfully identifies correct structures for targets where co-folding models fail. Ablation studies confirm that full-parameter fine-tuning of the AF-M components is critical for performance and reveal that, surprisingly, the inclusion of ESM embeddings can hinder success rates in certain cases. The code is available at https://github.com/Graylab/AF2Dock.",
        "category": "Poster",
        "location": " San Diego"
    },
    {
        "id": 23,
        "title": "Improved Therapeutic Antibody Reformatting through Multimodal Machine Learning",
        "authors": "Jiayi Xin, Aniruddh Raghu, Nick Bhattacharya, Adam Carr, Melanie Montgomery, Hunter Elliott",
        "abstract": "Modern therapeutic antibody design often involves composing multi-part assemblages of individual functional domains, each of which may be derived from a different source or engineered independently. While these complex formats can expand disease applicability and improve safety, they present a significant engineering challenge: the function and stability of individual domains are not guaranteed in the novel format, and the entire molecule may no longer be synthesizable. To address these challenges, we develop a machine learning framework to predict reformatting success -- whether converting an antibody from one format to another will succeed or not. Our framework incorporates both antibody sequence and structural context, incorporating an evaluation protocol that reflects realistic deployment scenarios. In experiments on a real-world antibody reformatting dataset, we find the surprising result that large pretrained protein language models (PLMs) fail to outperform simple, domain-tailored, multimodal representations. This is particularly evident in the most difficult evaluation setting, where we test model generalization to a new starting antibody. In this challenging \"new antibody, no data\" scenario, our best multimodal model achieves high predictive accuracy, enabling prioritization of promising candidates and reducing wasted experimental effort. ",
        "category": "Poster",
        "location": " San Diego"
    },
    {
        "id": 26,
        "title": "ChromWeave: Equivariant Generative Modeling of 3D Genome Organization",
        "authors": "Shuming Liu, Hongwei Tu, Lorenzo Bini, Jian Ma",
        "abstract": "Understanding the three-dimensional (3D) ensemble of chromosome conformations is essential, as dynamic structural states underlie diverse processes such as gene regulation, cell-type identity, and disease. However, systematically modeling how 1D epigenomic features give rise to 3D chromosome ensembles remains an unsolved challenge. Inspired by advances in protein structure prediction and modern generative modeling, we introduce ChromWeave, a symmetry-aware generative framework that couples flow matching with an equivariant neural network to directly generate physically realistic 3D chromosome ensembles from epigenomic signals. By enforcing physical symmetries, ChromWeave achieves orders-of-magnitude speedup over traditional physics-based simulations while producing experimentally consistent structural distributions. Trained on single-cell MERFISH chromosome imaging data and raw 1D epigenomic features, ChromWeave learns a continuous-time equivariant velocity field that maps simple prior distributions to realistic conformational distributions, avoiding large-scale pretraining and remaining highly data-efficient. Our results show that ChromWeave accurately captures both polymeric properties of chromosomes and genomic organizational features such as domains and boundaries that closely match MERFISH measurements. Together, ChromWeave provides a computationally efficient and physically grounded approach for mapping 1D epigenomic features to 3D genome ensembles, with the potential to generalize across genomic regions and ultimately scale to whole-genome modeling.",
        "category": "Poster",
        "location": " San Diego"
    },
    {
        "id": 29,
        "title": "SimpleFold: Folding Proteins is Simpler than You Think",
        "authors": "Yuyang Wang, Jiarui Lu, Navdeep Jaitly, Josh Susskind, Miguel Angel Bautista",
        "abstract": "Protein folding models have achieved groundbreaking results typically via a combination of integrating domain knowledge into the architectural blocks and training pipelines. Nonetheless, given the success of generative models across different but related problems, it is natural to question whether these architectural designs are a necessary condition to build performant models. In this paper, we introduce SimpleFold, the first flow-matching based protein folding model that solely uses general purpose transformer blocks. Protein folding models typically employ computationally expensive modules involving triangular updates, explicit pair representations or multiple training objectives curated for this specific domain. Instead, SimpleFold employs standard transformer blocks with adaptive layers and is trained via a generative flow-matching objective with an additional structural term. We scale SimpleFold to 3B parameters and train it on approximately 9M distilled protein structures together with experimental PDB data. On standard folding benchmarks, SimpleFold-3B achieves competitive performance compared to state-of-the-art baselines, in addition SimpleFold demonstrates strong performance in ensemble prediction which is typically difficult for models trained via deterministic reconstruction objectives. Due to its general-purpose architecture, SimpleFold shows efficiency in deployment and inference on consumer-level hardware. SimpleFold challenges the reliance on complex domain-specific architectures designs in protein folding, opening up an alternative design space for future progress.",
        "category": "Poster",
        "location": " San Diego"
    },
    {
        "id": 31,
        "title": "Learning residue level protein dynamics with multiscale Gaussians",
        "authors": "Mihir Bafna, Bowen Jing, Bonnie Berger",
        "abstract": "Understanding the structure dynamics of proteins is essential for elucidating biological function. We present \\textsc{DynaProt}, a lightweight, SE(3)-invariant framework that predicts rich descriptors of protein dynamics directly from static structures. By casting the problem through the lens of multivariate Gaussians, DynaProt estimates dynamics at two complementary scales: (1) per-residue marginal anisotropy as $3 \\times 3$ covariance matrices capturing local flexibility, and (2) joint scalar covariances encoding pairwise dynamic coupling across residues. DynaProt achieves high accuracy in predicting residue flexibility, marginal anisotropy, and, remarkably, enables reasonable reconstruction of the full covariance matrix for fast ensemble generation using orders of magnitude fewer parameters than prior methods. ",
        "category": "Poster",
        "location": " San Diego"
    },
    {
        "id": 32,
        "title": "Generating functional and multistate proteins with a multimodal diffusion transformer",
        "authors": "Bowen Jing, Anna Sappington, Mihir Bafna, Ravi Shah, Adrina Tang, Rohith Krishna, Adam Klivans, Daniel Diaz, Bonnie Berger",
        "abstract": "Generating proteins with the full diversity and complexity of functions found in nature is a grand challenge in protein design. Here, we present ProDiT, a multimodal diffusion model that unifies sequence and structure modeling paradigms to enable the design of functional proteins at scale. Trained on sequences, 3D structures, and annotations for 214M proteins across the evolutionary landscape, ProDiT generates diverse, novel proteins that preserve known active and binding site motifs and can be successfully conditioned on a wide range of molecular functions, spanning 465 Gene Ontology terms. We introduce a diffusion sampling protocol to design proteins with multiple functional states, and demonstrate this protocol by scaffolding enzymatic active sites from carbonic anhydrase and lysozyme to be allosterically deactivated by a calcium effector. Our results showcase ProDiT's unique capacity to satisfy design specifications inaccessible to existing generative models, thereby expanding the protein design toolkit.",
        "category": "Poster",
        "location": " San Diego"
    },
    {
        "id": 34,
        "title": "TLDR: RL-guided latent diffusion for de novo TCR design",
        "authors": "Soo Kim, Isidro Cortes-Ciriano",
        "abstract": "T cell receptor (TCR) design has been hindered by biased datasets that limit generalisation to novel epitopes. Consequently, existing models are restricted to only designing TCR\u2019s short binding region, CDR3b, for a small set of well-studied epitopes. We introduce TLDR, a framework that mitigates this challenge by fine-tuning an epitope-conditioned diffusion model with reinforcement learning guided by structural and biophysical constraints. By incentivising models with rewards that reflect complex properties, we (i) generate plausible TCR candidates for under-represented and unseen epitopes, (ii) guide generation into novel regions of the design space and (iii) reduce dependence on the training data for supervision. To the best of our knowledge, TLDR is the first model capable of designing full-length, paired TCRs. Crucially, TLDR matches the CDR3b-only baselines on binding specificity tasks on seen epitopes and outperforms them on unseen tasks. ",
        "category": "Poster",
        "location": " San Diego"
    },
    {
        "id": 35,
        "title": "g-DPO: Scalable Preference Optimization for Protein Language Models",
        "authors": "Constance Ferragu, Jonathan D. Ziegler, Nicolas Deutschmann, Arthur Lindoulsi, Eli Bixby",
        "abstract": "Direct Preference Optimization (DPO) is an effective approach for aligning protein language models with experimental design goals. However, DPO faces a scalability bottleneck: the number of possible training pairs grows quadratically with the number of labeled sequences, leading to prohibitive training times even for modestly sized datasets. We introduce g-DPO, a framework that (i) uses sequence space clustering to prune redundant pairs while preserving training signal, and (ii) amortizes likelihood computations with group-based approximations. Across three protein engineering tasks, g-DPO maintains _in-silico_ and _in-vitro_ performance that is statistically indistinguishable from standard DPO, while converging $1.8$ to $3.7$ times faster, with greater gains expected as the size of the dataset increases.",
        "category": "Poster",
        "location": " Copenhagen"
    },
    {
        "id": 39,
        "title": "A deep learning approach for rational affinity maturation of anti-VEGF nanobodies",
        "authors": "Ga\u00eblle Verdon, Laurent David, Alexandre de Brevern, Yasser  Mohseni Behbahani",
        "abstract": "Nanobodies offer several advantages over conventional antibodies due to their lower immunogenicity, enhanced stability, and superior tissue penetration, making them promising candidates for cancer therapy. In this study, we employ deep learning algorithms to design anti-VEGF nanobodies via affinity maturation. Our approach integrates structure-guided mutational modeling and systematic measurement of binding affinity and stability for rational optimization of Complementarity Determining Regions. In addition, we developed a sequence-based melting temperature predictor for nanobodies, ensuring stability of the designed mutants. Our method achieves energy reductions up to -4.92 kcal/mol. Our melting temperature predictor demonstrated a Pearson correlation coefficient of 0.772. These findings emphasize the potential of computational approaches for nanobody affinity maturation and stability prediction, paving the way for more effective therapeutic designs.",
        "category": "Poster",
        "location": " Copenhagen"
    },
    {
        "id": 40,
        "title": "PairSAE: Mechanistic Interpretability from Pair Representations in Protein Co-Folding",
        "authors": "Giosue Migliorini, Aristofanis Rontogiannis, Grigori Guitchounts, Nicholas Franklin, Axel Elaldi, Olivia Viessmann",
        "abstract": "Foundation models for structural biology have achieved remarkable performance in predicting biomolecular structure and show promise for the design of proteins and small molecules. Yet understanding \\emph{which} internal features drive their outputs remains challenging. Standard sparse autoencoders (SAEs), effective on transformer-style \\emph{sequence embeddings}, do not transfer cleanly to pairformer-like architectures: na\u00efvely operating on pairwise representations yields a quadratic blow-up of features and obscures concepts distributed jointly across sequence and pair representations. Foundation models for structural biology have achieved remarkable performance in predicting biomolecular structure and show promise for the design of proteins and small molecules. Yet understanding \\emph{which} internal features drive their outputs remains challenging. Standard sparse autoencoders (SAEs), effective on transformer-style \\emph{sequence embeddings}, do not transfer cleanly to pairformer-like architectures: na\u00efvely operating on pairwise representations yields a quadratic blow-up of features and obscures concepts distributed jointly across sequence and pair representations. We introduce \\textit{PairSAE}, which summarizes pairwise tensors via an $N$-mode SVD into token-wise interaction roles, then uses a sparse autoencoder to learn a \\emph{shared} set of token-level features that decode into both sequence and pair representations. Evaluated on Boltz-2 activations for PLINDER protein\u2013ligand complexes, PairSAE yields interpretable features that align with UniProt annotations and predict Boltz-2 affinity values. These results indicate that PairSAE links the latent space of foundation models for structural biology to interpretable structural concepts, clarifying what the model \u201cknows\u201d while avoiding pairformer-induced pitfalls that limit conventional SAEs.",
        "category": "Poster",
        "location": " San Diego"
    },
    {
        "id": 42,
        "title": "Improved De Novo Peptide Binder Design with Target-Conditioned Inverse Folding",
        "authors": "Elliot Layne, Ashlin Kanawaty, Aron Broom, Alexander Kitaygorodsky, Anita Nivedha, Parth Vora, Caroline Woffindale, Sarah Hailstone, Eirini Sachouli, Ella Halcrow, Gillian Donachie, Michelle Adsett, Glenn Butterfoss, Mark Fingerhuth",
        "abstract": "Inverse protein folding methods have become central to the computational design of de novo proteins, but existing models struggle when tasked with generating high-affinity peptide binders. By combining peptide-specific finetuning with a novel decoding order strategy, we enhance pocket conditioning and enable more accurate sequence design for peptide-binding interfaces. Our approach delivers gains in computational metrics, increasing sequence recovery and improving in silico binder design success rate by 16\\%-30\\%. In vitro validation finds that our method greatly improves the success rate of designing novel peptide agonists of the OPRM1 receptor, generating at least twice as many top-ranking agonists as prevailing standard method ProteinMPNN.",
        "category": "Poster",
        "location": " San Diego"
    },
    {
        "id": 43,
        "title": "Conditional Protein Structure Generation with Protpardelle-1c",
        "authors": "Tianyu Lu, Richard Shuai, Petr Kouba, Zhaoyang Li, Yilin Chen, Akio Shirali, Jinho Kim, Po-Ssu Huang",
        "abstract": "We present Protpardelle-1c, a collection of protein structure generative models with robust motif scaffolding and support for multi-chain complex generation under hotspot-conditioning. Enabling sidechain-conditioning to a backbone-only model increased Protpardelle-1c's MotifBench score from 4.97 to 28.16, outperforming RFdiffusion's 21.27. The crop-conditional all-atom model achieved 208 unique solutions on the La-Proteina all-atom motif scaffolding benchmark, on par with La-Proteina while having ~10 times fewer parameters. At 25M parameters, Protpardelle-1c enables rapid sampling, taking 40 minutes to sample all 3000 MotifBench backbones on an NVIDIA A100-80GB, compared to 31 hours for RFdiffusion.",
        "category": "Poster",
        "location": " San Diego"
    },
    {
        "id": 44,
        "title": "MSACLR: Contrastive Learning of Protein Conformations from MSAs",
        "authors": "JUNJIE ZHANG, XIAOLIN CHENG, ENMING XING",
        "abstract": "We propose MSACLR ( Multiple Sequence Alignment Contrastive Learning Representation), a two-stage contrastive learning framework that maps MSA space to conformational space. In Stage 1, embeddings are trained to discriminate structural folds across diverse proteins using only MSA information. In Stage 2, embeddings are fine-tuned on subMSAs labeled by their associated predicted structural clusters, enabling discrimination of alternative conformations within the same protein. To enrich training data, we introduce BLOSUM62-guided  augmentation, which expands the pool of subMSAs associated with each structural cluster label by introducing sequence-level diversity. Our experiments show that MSACLR embeddings achieve clearer fold-level separation than single-sequence baselines, while fine-tuned embeddings capture conformational variation across scale -from local loop motions to domain motions and fold switching. MSACLR provides a foundation for efficient exploration of MSA space and enables sampling of conformational ensembles, bridging the gap between static structure prediction and dynamic protein behavior.",
        "category": "Poster",
        "location": " San Diego"
    },
    {
        "id": 47,
        "title": "Ensemble-conditioned protein sequence design with Caliby",
        "authors": "Richard Shuai, Tianyu Lu, Subhang Bhatti, Petr Kouba, Possu Huang",
        "abstract": "Structure-conditioned sequence design models aim to design a protein sequence that will fold into a given target structure. Deep-learning-based approaches for sequence design have proven highly successful for various protein design applications, but many non-idealized backbones still remain out of reach for current models under typical in silico success criteria. We hypothesize that training objectives prioritizing native sequence recovery unintentionally push models to reproduce non-structural signals (e.g. phylogenetic relatedness, neutral drift, or dataset sampling biases), rather than a broadly generalizable structure-sequence mapping. Inspired by recent work bridging sequence likelihood and fitness prediction in protein language models, we introduce Caliby, a Potts model-based sequence design method capable of conditioning on an ensemble of structures. Conditioning on a synthetic ensemble generated from an input backbone allows sampling of sequences consistent with the structural constraints of the ensemble while averaging out undesired biases towards the native sequence. Ensemble-conditioned sequence design with Caliby reduces native sequence recovery while substantially improving AlphaFold2 self-consistency, outperforming state-of-the-art models ProteinMPNN and ChromaDesign on both native and de novo backbones. These results suggest that Caliby can expand the de novo design space beyond highly idealized backbones.",
        "category": "Contributed talk",
        "location": " San Diego"
    },
    {
        "id": 57,
        "title": "Multi-Scale Protein Structure Modelling with Geometric Graph U-Nets",
        "authors": "Chang Liu, Vivian Li, Linus Leong, Vladimir Radenkovic, Pietro Lio, Chaitanya K. Joshi",
        "abstract": "Geometric Graph Neural Networks (GNNs) and Transformers have become state-of-the-art for learning from 3D protein structures. However, their reliance on local message passing prevents them from capturing the hierarchical interactions that govern protein function, such as global domains and long-range allosteric regulation.  In this work, we argue that the network architecture itself should mirror this biological hierarchy. We introduce Geometric Graph U-Nets, a new class of models that learn multi-scale representations by recursively coarsening and refining the protein graph. We prove that this hierarchical design is theoretically as or more expressive than standard Geometric GNNs. Empirically, on the task of protein fold classification, Geometric U-Nets substantially outperform invariant and equivariant baselines, demonstrating their ability to learn the global structural patterns that define protein folds. Our work provides a principled blueprint for designing next-generation geometric architectures that can learn the multi-scale structure of biomolecules.",
        "category": "Poster",
        "location": " Copenhagen"
    },
    {
        "id": 58,
        "title": "Computational Design of Monomeric Variants of Multimeric Enzymes",
        "authors": "Jakub L\u00e1la, Arnav Cheruku, Stefano Angioletti-Uberti",
        "abstract": "Multimeric enzymes often place catalytic residues at subunit interfaces, coupling activity to correct assembly and concentration. The need for correct assembly from multiple units complicates bacterial expression, scale-up, and implementation into industrial bioprocesses. By construction, a single-chain monomer folding into the exact same active-site geometry could, in principle, alleviate these challenges, while still retaining its catalytic activity. Following this reasoning, we present a general computational design protocol to monomerize multimeric enzymes while preserving their active-site geometry. Our method combines Monte Carlo optimization with an energy-based formalism, specifying design constraints as energy terms defined through the outputs of a protein-folding algorithm. Specifically, by driving the sequence search to active-site geometries close to that of the multimeric enzyme, we generate monomeric variants with low RMSD to the multimeric active site, in line with commonly used thresholds to filter potential candidates for lab testing. As a case study, we redesign the homotetrameric formolase enzyme, a critical synthetic enzyme for conversion of carbon dioxide into valuable C3 chemicals. Given the protocol\u2019s generality, we believe these results represent an important foundational step toward speeding up the search for industrially practical synthetic enzyme mimics.",
        "category": "Contributed talk",
        "location": " Copenhagen"
    },
    {
        "id": 59,
        "title": "SynthFormer: Equivariant Pharmacophore-based Generation of Synthesizable Molecules for Ligand-Based Drug Design",
        "authors": "Zygimantas  Jocys, Zhanxing Zhu, Henriette Willems, Katayoun Farrahi",
        "abstract": "Drug discovery is a complex process requiring significant time and cost to bring new medicines to patients. Many generative models aim to accelerate drug discovery, but few produce synthetically accessible molecules. Conversely, synthesis-focused models do not leverage the 3D information crucial for effective drug design. We introduce SynthFormer, a novel machine learning model that generates fully synthesizable molecules, structured as synthetic trees, by introducing  3D pharmacophores as input. SynthFormer features a 3D equivariant graph neural network to encode pharmacophores, followed by a Transformer-based synthesis-aware decoding mechanism for constructing synthetic trees as a sequence of tokens. It is a first-of-its-kind approach that could provide capabilities for designing active molecules based on pharmacophores, performing hit expansion and optimizing their properties. We demonstrate its effectiveness through various challenging tasks, including designing active compounds for a range of proteins, performing hit expansion and optimizing molecular properties.",
        "category": "Poster",
        "location": " Copenhagen"
    },
    {
        "id": 60,
        "title": "Stoic: Fast and accurate protein stoichiometry prediction",
        "authors": "Daniil Litvinov, Lorenzo Pantolini, Peter \u0160krinjar, Gerardo Tauriello, Caitlyn McCafferty, Benjamin Engel, Torsten Schwede, Janani Durairaj",
        "abstract": "Protein structure prediction methods require prior knowledge of protein stoichiometry - the number of copies of each protein entity within a complex. Current approaches rely on computationally expensive brute-force methods that run structure prediction on multiple stoichiometry combinations, often with limited accuracy. We introduce Stoic, a method that uses protein language model embeddings to predict protein complex stoichiometry. Our approach learns to identify interface residues that participate in protein-protein interactions, rather than relying on global sequence features. By integrating these interface-aware embeddings into a graph neural network, Stoic achieves fast and accurate stoichiometry prediction for both homomeric and heteromeric targets.",
        "category": "Poster",
        "location": " Copenhagen"
    },
    {
        "id": 61,
        "title": "De novo generation of functional terpene synthases using TpsGPT",
        "authors": "Hamsini Ramanathan, Roman Bushuiev, Matou\u0161 Sold\u00e1t, Ji\u0159\u00ed Kohout, T\u00e9o Hebra, Joshua David Smith, Josef Sivic, Tom\u00e1\u0161 Pluskal",
        "abstract": "Terpene synthases (TPS) are a key family of enzymes responsible for generating the diverse terpene scaffolds that underpin many natural products, including front-line anticancer drugs such as Taxol. However, de novo TPS design through directed evolution is costly and slow. We introduce TpsGPT, a generative model for scalable TPS protein design, built by fine-tuning the protein language model ProtGPT2 on 79k TPS sequences mined from UniProt. TpsGPT generates de novo enzyme candidates in silico and evaluates them using multiple validation metrics, including EnzymeExplorer classification, ESMFold structural confidence (pLDDT), sequence diversity, CLEAN classification, InterPro domain detection, and Foldseek structure alignment. From an initial pool of 28k generated sequences, we identified seven putative TPS enzymes that satisfied all validation criteria. Experimental validation confirmed TPS enzymatic activity in at least two of these sequences. Our results show that fine-tuning of a protein language model on a carefully curated, enzyme-class-specific dataset, combined with rigorous filtering, can enable the de novo generation of functional, evolutionarily distant enzymes.",
        "category": "Poster",
        "location": " San Diego"
    },
    {
        "id": 63,
        "title": "ProteomeLM: A proteome-scale language model enables accurate and rapid prediction of protein-protein interactions",
        "authors": "Cyril Malbranke, Gionata Paolo Zalaffi, Anne-Florence Bitbol",
        "abstract": "Language models trained on biological sequences are advancing inference tasks from the scale of single proteins to that of genomic neighborhoods. Here, we introduce ProteomeLM, a transformer-based language model that uniquely operates on entire proteomes from species spanning the tree of life. ProteomeLM is trained to reconstruct masked protein embeddings using the whole proteomic context, yielding contextualized protein representations that reflect proteome-scale functional constraints. ProteomeLM spontaneously captures protein-protein interactions (PPI) in its attention coefficients. Furthermore, it enables interactome-wide PPI screening that is substantially more accurate, and orders of magnitude faster, than amino-acid coevolution-based methods. We further develop ProteomeLM-PPI, a supervised model that combines ProteomeLM embeddings and attention coefficients to achieve state-of-the-art PPI prediction across benchmarks and species. Our results demonstrate the potential of proteome-scale language models for addressing function and interactions at the organism level. Data and code are made (anonymously) available at https://anonymous.4open.science/r/ProteomeLM-anonymized",
        "category": "Contributed talk",
        "location": " Copenhagen"
    },
    {
        "id": 67,
        "title": "PrOMet: Accurate and Robust Metal-binding site and Type Prediction",
        "authors": "Gangeun Park, Hahnbeom Park, Chaok Seok",
        "abstract": "  Metal binding to proteins is crucial for many biological functions, yet the prediction of metal-binding sites and metal types remains underexplored compared to other biomolecular interactions. Despite advances in deep learning, computational methods have achieved limited success in this area; even the best-reported approaches reach only moderate localization accuracy on high-resolution crystal structures, and even worse when applied to medium-resolution data. We hypothesize that the main challenge lies in the nature of metal binding: while the putative sites span the entire protein surface, actual binding requires the atomic-level coordination geometry. We present a structure-based metal binding site and type predictor, PrOMet, in this work, which leverages a Prune-and-Optimization strategy built upon two hierarchically connected machine learning architectures. This strategy allows the method to effectively narrow the search space while maintaining robustness to AlphaFold models and medium-resolution cryo-EM structures. PrOMet outperforms existing methods, including structure-based and language model-based predictors, achieving a PR-AUC of 0.739 for metal ion localization and an average F1-score of 0.743 for metal type classification\u2014Zn, Ca, Mg, Mn, Fe, Cu, respectively. PrOMet can be an effective tool for allocating uncertain metal positions and types within protein structures, as well as for metalloenzyme design studies.",
        "category": "Poster",
        "location": " Copenhagen"
    },
    {
        "id": 68,
        "title": "Rewriting protein alphabets with language models",
        "authors": "Lorenzo Pantolini, Gabriel Studer, Laura Engist, Ieva Pudziuvelyte, Florian Pommerening, Andrew Mark Waterhouse, Gerardo Tauriello, Martin Steinegger, Torsten Schwede, Janani Durairaj",
        "abstract": "Detecting remote homology with speed and sensitivity is crucial for tasks like function annotation and structure prediction. We introduce a novel approach using contrastive learning to convert protein language model embeddings into a new 20-letter alphabet, TEA, enabling highly efficient large-scale protein homology searches. Searching with our alphabet performs on par with and complements structure-based methods without requiring any structural information, and with the speed of sequence search. Ultimately, we bring the exciting advances in protein language model representation learning to the plethora of sequence bioinformatics algorithms developed over the past century, offering a powerful new tool for biological discovery.",
        "category": "Contributed talk",
        "location": " Copenhagen"
    },
    {
        "id": 69,
        "title": "Design of peptides with non-canonical amino acids using flow matching",
        "authors": "Jin Sub Lee, Philip Kim",
        "abstract": "The canonical vocabulary of twenty amino acids limits the chemical space available to proteins and peptides. Expanding this vocabulary to hundreds of non-canonical amino acids allows the engineering of proteins with novel function and activity, and is of great interest for the discovery of novel drugs such as macrocyclic peptides. Here we present NCFlow, a flow-based generative model capable of incorporating any arbitrary non-canonical amino acid into a given protein. To supplement sparse training data in the Protein Data Bank, NCFlow is pretrained on millions of small molecule structures and a large set of protein-ligand complexes before finetuning on native non-canonicals found within proteins in the Protein Data Bank. We show that NCFlow outperforms AlphaFold3-based methods in the structure prediction of unseen non-canonical amino acids. We present a peptide design pipeline akin to in silico deep mutational scanning, and propose a novel scoring strategy using a combination of deep learning-based and molecular dynamics-based alchemical binding free energy calculations to identify improved peptide variants. We apply the method on four protein-peptide complex test cases, and observe that incorporating non-canonicals can significantly improve binding affinity by up to -7.0 kcal/mol. Thus, NCFlow can be easily integrated into existing protein design platforms to further improve its properties outside of what is capable with standard amino acids.",
        "category": "Poster",
        "location": " San Diego"
    },
    {
        "id": 70,
        "title": "FALCON: Few-step Accurate Likelihoods for Continuous Flows",
        "authors": "Danyal Rehman, Tara Akhound-Sadegh, Artem Gazizov, Yoshua Bengio, Alexander Tong",
        "abstract": "Scalable sampling of molecular states in thermodynamic equilibrium is a long-standing challenge in statistical physics. Boltzmann Generators tackle this problem by pairing a generative model, capable of exact likelihood computation, with importance sampling to obtain consistent samples under the target distribution. Current Boltzmann Generators primarily use continuous normalizing flows (CNFs) trained with flow matching for efficient training of powerful models. However, likelihood calculation for these models is extremely costly, requiring thousands of function evaluations per sample, severely limiting their adoption. In this work, we propose Few-step Accurate Likelihoods for Continuous (FALCON) Flows, a method which allows for few-step sampling with a likelihood accurate enough for importance sampling applications by introducing a hybrid training objective that encourages invertibility. We demonstrate that FALCON outperforms state-of-the-art normalizing flow models for molecular Boltzmann sampling and is two orders of magnitude faster than the most performant CNFs.",
        "category": "Poster",
        "location": " San Diego"
    },
    {
        "id": 72,
        "title": "Improving RNA 3D Structure Prediction via Language Model-Augmented AlphaFold 3",
        "authors": "Shuxian Zou, Jiayou Zhang, Bingkang Zhao, Hui Li, Eric Xing, Le Song",
        "abstract": "Predicting RNA 3D structure from sequence remains challenging due to the structural flexibility of RNA molecules and the scarcity of experimentally resolved structures. We ask how self-supervised RNA language models (LMs), trained on millions of RNA sequences, can best enhance AlphaFold 3 (AF3) for RNA structure prediction. Using an open-source AF3 reproduction, we run controlled experiments that fix data and hyperparameters while varying fusion position and method.  We find large performance variations between fusion strategies, and without Multiple Sequence Alignment (MSA), they are generally not effective. When incorporating MSA, the most effective approach is additive fusion applied at the late stage of the conditional network, refining AF3\u2019s single representations with RNA LM embeddings. On RecentPDB-RNA (47 newly released targets), our best model achieves an average TM-score of 0.438 and a success rate of 30\\% (TM-score $\\ge$ 0.6), significantly outperforming all baseline models. On 11 CASP16-RNA targets, it matches the best automated system trRosettaRNA. These results show that properly fused RNA LM features substantially advance RNA 3D structure prediction. ",
        "category": "Poster",
        "location": " Copenhagen"
    },
    {
        "id": 74,
        "title": "Look mom, no experimental data! Learning to score protein-ligand interactions from simulations",
        "authors": "Michael Brocidiacono, James Wellnitz, Konstantin Popov, Alexander Tropsha",
        "abstract": "Despite recent advances in protein-ligand structure prediction, deep learning methods remain limited in their ability to accurately predict binding affinities, particularly for novel protein targets dissimilar from the training set. In contrast, physics-based binding free energy calculations offer high accuracy across chemical space but are computationally prohibitive for large-scale screening. We propose a hybrid approach that approximates the accuracy of physics-based methods by training target-specific neural networks on molecular dynamics simulations of the protein in complex with random small molecules. Our method uses force matching to learn an implicit free energy landscape of ligand binding for each target. Evaluated on six proteins, our approach achieves competitive virtual screening performance using 100-500 \u03bcs of MD simulations per target. Notably, this approach achieves state-of-the-art early enrichment when using the true pose for active compounds. These results highlight the potential of physics-informed learning for virtual screening on novel targets.",
        "category": "Poster",
        "location": " San Diego"
    },
    {
        "id": 75,
        "title": "forge: sequence-based binder design with latent flow matching",
        "authors": "Young Su Ko",
        "abstract": "We present forge-v0, a sequence-based flow matching model for protein binder design. Drawing parallels from text-to-image generation, we treat binder design as a target-to-binder generation task. Rather than the text encoder and variational autoencoder typically used for text and images respectively, we leverage Raygun, a pre-trained autoencoder for protein sequence to represent both the target and binder. Using a state-of-the-art flow matching architecture, we trained forge-v0 on ~10M protein-protein interactions from the STRING database, rather than complex structures from the Protein Data Bank, learning a broader distribution of natural interactions. In our proof-of-concept evaluation, we performed an in silico binder design benchmark, in which forge-v0 generated binders with higher structure-based metrics (ipTM and ipSAE) than RFDiffusion on 10/11 targets. These results motivate further development of forge towards designing and validating binders against therapeutically relevant targets out of reach for structure-based approaches.",
        "category": "Poster",
        "location": " San Diego"
    },
    {
        "id": 77,
        "title": "FlashAffinity: Bridging the Accuracy-Speed Gap in Protein-Ligand Binding Affinity Prediction",
        "authors": "Songlin Jiang, Yifan Chen, Ze Cao, Wengong Jin",
        "abstract": "Accurate prediction of protein-ligand binding affinity is central to computational drug discovery. Recent foundation models, such as Boltz-2, have achieved remarkable accuracy, but their high computational cost poses a major barrier to large-scale virtual screening. We address this challenge by introducing a lightweight structure-based virtual screening model, FlashAffinity, that achieves similar performance as Boltz-2 in affinity prediction and binder classification tasks, while achieving a 50x speedup at inference time. FlashAffinity replaces the expensive protein structure prediction models with a simple protein-ligand docking model and the PairFormer-based affinity scoring module with a cheap EGNN architecture. In summary, this work bridges the gap between accuracy and efficiency, enabling ultra-fast virtual screening of massive chemical libraries.",
        "category": "Poster",
        "location": " San Diego"
    },
    {
        "id": 80,
        "title": "Synthetic Evolution of Enzyme Specificity with a Self-Driving Laboratory",
        "authors": "Coban Brooks, Pascal Notin, Jacob Rapp, Philip Romero",
        "abstract": "Engineering enzymes with tailored substrate specificities holds immense promise for biotechnology, but current approaches are slow, labor-intensive, and prone to failure. We present Robot Orchestrated Synthetic Evolution (ROSE), a closed-loop platform that integrates a self-driving laboratory with a transformer-based surrogate model and Bayesian optimization to autonomously explore protein fitness landscapes. ROSE expands beyond traditional directed evolution by exploring non-linear evolutionary trajectories, enabling escape from local optima. We demonstrate this system by engineering beta-glucosidase enzymes with altered substrate specificity, achieving up to a 13-fold improvement in specificity on non-native substrates. Beyond this case study, we show that ROSE reliably identifies top-performing variants across diverse protein datasets while experimentally testing only a small fraction of available sequences. Together, ROSE establishes a modular and general-purpose framework for fully autonomous protein engineering.",
        "category": "Poster",
        "location": " Copenhagen"
    },
    {
        "id": 81,
        "title": "Do biological autoregressive models learn protein coevolution?",
        "authors": "Xiaonan Liu",
        "abstract": "Autoregressive protein and genomic language models have shown remarkable success in designing proteins. However, it is unclear whether they, like masked protein language models, ESM2, have also learned protein coevolution. We applied the unsupervised Categorical Jacobian method to extract protein coevolutionary contacts across 105 proteins from ProGen3, Evo and Evo2. All autoregressive models demonstrated substantially lower contact recovery compared to the masked langauge model ESM2 (model with the best performance: ProGen3 P@L=0.077 vs ESM2=0.450). While scaling improved contact detection, even the largest model, ProGen3 46B, performed better than random in only 31 out of 105 proteins. We hypothesize that autoregressive models primarily learn dependencies between sequence fragments rather than residue-level coevolution, with fragments shorten as models scale. This limitation may explain why current autoregressive models often require generating millions of sequences followed by extensive post hoc filtering to obtain viable designs and why their generations have high sequence identity to the natural proteins, limiting their degree of novelty. Our findings provide insights into how autoregressive models generate successful designs and suggest directions for improving novel sequence generation.",
        "category": "Poster",
        "location": " San Diego"
    },
    {
        "id": 82,
        "title": "SwitchCraft: Programmatic Design of State-Switching Proteins",
        "authors": "Bowen Jing, Mihir Bafna, Adam Klivans, Bonnie Berger",
        "abstract": "Complex multistate functional mechanisms are observed ubiquitously in natural proteins, yet the path towards systematic de novo rational design of such mechanisms remains unclear, despite significant advancements in protein language models and structure diffusion models. We introduce SwitchCraft, a versatile and programmatic framework for state-switching proteins based on backpropagation through compositional design constraints parameterized by structure prediction models. Our in silico evaluations demonstrate success on a wide range of state-switching design specifications, from allosteric regulation of functional motifs to discrimination of bound ligand identities. Notably, one design exhibits a 3.8 A conformational change upon oxygenation of heme, mimicking mechanisms of cooperativity in hemoglobin. These results position SwitchCraft at the inception of a powerful paradigm for higher-order functional protein design.",
        "category": "Contributed talk",
        "location": " San Diego"
    },
    {
        "id": 84,
        "title": "Backprop-based Motif Scaffolding Beats Generative Models",
        "authors": "Anisha Parsan, Bowen Jing, Bonnie Berger",
        "abstract": "Designing protein backbones that scaffold functional motifs is a central task in de novo protein design. Current state-of-the-art methods are based on generative models, yet they require extensive sampling and filtering of structures, typically resulting in low in silico success rates. Here, we revisit backprop-based design and systematically evaluate ColabDesign\u2019s protocol for motif scaffolding. Remarkably, we find that this protocol, which we call MotifCraft, outperforms all known methods on the standard 24-motif RFDiffusion benchmark, ranking first on 17 motifs, improving the median unique success rate 8.5x from 0.7% to 5.9%, and substantially exceeding recent generative models like Prote\u00edna. Detailed error analysis reveals that, for the most difficult motifs, MotifCraft attains an even higher success rate when considering only design trajectories that terminate in structures containing the motif. These results establish backprop-based optimization as the state-of-the-art strategy for motif scaffolding and challenge the prevailing assumption that generative models are necessary for this task.",
        "category": "Poster",
        "location": " San Diego"
    },
    {
        "id": 93,
        "title": "Conformational Rank Conditioned Committees for Machine Learning-Assisted Directed Evolution",
        "authors": "Mia Adler, Shiyuan Liang, Tianzhen Peng, Oleg Presnyakov, Justin Baker, Jannelle Lauffer, Himani Sharma, Barry Merriman",
        "abstract": "Machine Learning-assisted directed evolution (MLDE) is a powerful tool for efficiently navigating antibody fitness landscapes. Many structure-aware MLDE pipelines rely on a single conformation or a single committee across all conformations, limiting their ability to separate conformational uncertainty from epistemic uncertainty. Here, we introduce a rank -conditioned committee (RCC) framework that leverages ranked conformations to assign a deep neural network committee per rank. This design enables a principled separation between epistemic uncertainty and conformational uncertainty. We validate our RCC-MLDE approach on SARS-CoV-2 antibody docking, demonstrating significant improvements over baseline strategies. Our results offer a scalable route for therapeutic antibody discovery while directly addressing the challenge of modeling conformational uncertainty.",
        "category": "Poster",
        "location": " San Diego"
    },
    {
        "id": 94,
        "title": "Inferring Local Protein Structural Similarity from Sequence Alone",
        "authors": "Zinnia Ma, Javier Espinoza Herrera, Neville Bethel, Adrian Jinich",
        "abstract": "Detecting structural similarity at the local level between proteins is central to understanding function and evolution, yet most approaches require 3D models. In this work, we show that protein language models (pLMs), solely using sequence data as input, implicitly capture fine-grained structural signals that can be leveraged to identify such similarities. By mean-pooling residue embeddings over sliding windows and comparing them across proteins with cosine similarity, we find diagonal patterns that reflect locally aligned regions even without sequence identity. Building on this insight, we introduce a framework for detecting locally aligned structural regions directly from sequences, supporting the development of scalable methods for structural annotation and comparison.",
        "category": "Poster",
        "location": " San Diego"
    },
    {
        "id": 104,
        "title": "DiffAlign: Diffusion-Based Molecular Alignment with Pocket-Aware Guidance",
        "authors": "Iljung Kim, Keehyoung Joo, Yung-Kyun Noh",
        "abstract": "We introduce DiffAlign, a conditional E(3)-equivariant diffusion framework that incorporates receptor context directly into the sampling process. We demonstrate its application to flexible molecular alignment, which requires jointly exploring a ligand\u2019s intramolecular conformation and a pocket-compatible pose relative to a reference ligand. At inference time, DiffAlign injects universal force field (UFF) gradients on the ligand\u2013pocket system, steering trajectories toward low-energy, clash-free, pocket-aware poses without retraining. This inference-time physical guidance contrasts with approaches that incorporate receptor information only post hoc, leaving the generative trajectory unguided. On the DISCO cross-docking benchmark (a curated set of protein-ligand complexes), pocket-aware guidance improves Top-1 success rate over a no-steering baseline by +1.0/+1.7/+2.1 percentage points at 1/2/3 \u00c5 (\u223c10\u201320% relative; up to 20% at 1 \u00c5) and consistently outperforms ligand-only guidance. PoseBusters, a recent validation suite for stereochemical plausibility, further confirms chemical validity (\u226597% for local geometry; \u226595% for clash avoidance). Furthermore, DiffAlign produces diverse candidate sets, highlighting headroom for rescoring and integration into downstream tasks such as docking and virtual screening.",
        "category": "Poster",
        "location": " San Diego"
    },
    {
        "id": 106,
        "title": "BioBlobs: Differentiable Graph Partitioning for Protein Representation Learning",
        "authors": "Xin Wang, Carlos Oliver",
        "abstract": "Protein function is driven by coherent substructures that vary in size and topology, yet current protein representation learning models (PRL) distort these signals by relying on rigid substructures such as k-hop and fixed radius neighbourhoods.  We introduce BioBlobs, a plug-and-play, fully differentiable module that represents proteins by dynamically partitioning structures into flexibly-sized, non-overlapping substructures (``blobs\u201d). The resulting blobs are quantized into a shared and interpretable codebook, yielding a discrete vocabulary of function-relevant protein substructures used to compute protein embeddings. We show that BioBlobs representations improve the performance of widely used protein encoders such as GVP-GNN across various PRL tasks.  Our approach highlights the value of architectures that directly capture function-relevant protein substructures, enabling both improved predictive performance and mechanistic insight into protein function.  Source code: https://github.com/OliverLaboratory/BioBlobs",
        "category": "Poster",
        "location": " San Diego"
    },
    {
        "id": 108,
        "title": "OMTRA: A Multi-Task Generative Model for Structure-Based Drug Design",
        "authors": "Ian Dunn, Liv Toft, Tyler Katz, Juhi Gupta, Riya Shah, Ramith Hettiarachchi, David Koes",
        "abstract": "Structure-based drug design (SBDD) focuses on designing small-molecule ligands that bind to specific protein pockets. Computational methods are integral in modern SBDD workflows and often make use of virtual screening methods via docking or pharmacophore search. Modern generative modeling approaches have focused on improving novel ligand discovery by enabling \\textit{de novo} design. In this work, we recognize that these tasks share a common structure and can therefore be represented as different instantiations of a consistent generative modeling framework. We propose a unified approach in OMTRA, a multi-modal flow matching model that flexibly performs many tasks relevant to SBDD, including some with no analogue in conventional workflows. Additionally, we curate a dataset of 500M 3D molecular conformers, complementing protein\u2013ligand data and expanding the chemical diversity available for training. OMTRA obtains state-of-the-art performance on pocket-conditioned \\textit{de novo} design and docking; however, the effects of large-scale pretraining and multi-task training are modest. All code, trained models, and dataset for reproducing this work are available at https://github.com/gnina/OMTRA",
        "category": "Poster",
        "location": " San Diego"
    },
    {
        "id": 110,
        "title": "Improving scoring functions for protein-protein docking with LambdaLoss",
        "authors": "Richard Zhu, Darren Xu, Lee-Shin Chu, Jeffrey Gray",
        "abstract": "Modeling protein-protein interactions requires accurate scoring functions that can rank potential poses (conformations) of a protein-protein complex to differentiate near-native poses from incorrect ones. Here, we propose a general framework for improving protein-protein pose ranking models and other biomolecular interaction models using the LambdaLoss loss function from the Learning-to-Rank subfield. We test this framework by fine-tuning the energy prediction head of DFMDock with the LambdaLoss on an augmented dataset of 2.9M decoy poses derived from the DIPS dataset. On targets from the CAPRI score set benchmark, our fine-tuned ranking model LambdaDockScore is better at identifying correct poses in its top-1 and top-5 predictions compared to EuDockScore, a state-of-the-art method. LambdaDockScore also improves upon baseline DFMDock ranking performance for scoring antibody-antigen complexes and protein-protein complexes with very large or small binding interfaces.",
        "category": "Poster",
        "location": " San Diego"
    },
    {
        "id": 112,
        "title": "Real-time Forecasting of Influenza Evolution",
        "authors": "Aarushi Mehrotra, Navami Jain, Noor Youssef, Sarah Gurev, Debora Marks",
        "abstract": "Influenza A subtypes H1N1 and H3N2 are endemic in humans, with their high mutation rates requiring annual vaccine updates. However, vaccine strain selection currently relies on early neutralization assays and global surveillance data, resulting in mismatches between vaccine strains and circulating strains and ultimately reduce vaccine effectiveness. Accurately quantifying the impact of mutations on viral fitness and antigenicity could improve forecasting of emerging stains and enable more effective vaccine design. To address this, we track the phylogeny of H1N1 and H3N2 over the last 15 years to create forecasting benchmark datasets and evaluate state-of-the-art computational models for predicting their evolution. We find that computational models consistently outperformed experimental approaches at predicting new single mutations, with notable differences in performance across the strains. Finally, we study a period of high H1N1 incidence to explore how models can transfer learned evolutionary constraints across influenza subtypes. This work highlights the potential of deep learning models to forecast influenza evolution and support proactive vaccine design.",
        "category": "Poster",
        "location": " Copenhagen"
    },
    {
        "id": 113,
        "title": "All-atom protein design via SE(3) flow matching with ProteinZen",
        "authors": "Alex Li, Tanja Kortemme",
        "abstract": "The advent of generative models of protein structure has greatly accelerated our ability to perform de novo protein design, especially concerning design at coarser physical scales such as backbone generation and protein binder design. However, the design of precise placements at atomic scales remains a challenge for existing design methods. One avenue towards higher fidelity atomic-scale design is via generative models with full atomic resolution, but is complicated by the intricacies of simultaneously designing both discrete protein sequence and continuous atomic positionings. In this work we propose a framework to capture this interplay by decomposing residues into collections of oriented rigid bodies, allowing us to apply SE(3) flow-matching for all-atom protein structure generation. Our method, ProteinZen, generates designs with high sequence-structure consistency while retaining competitive diversity and novelty on both unconditional and conditional generation tasks. We demonstrate competitive performance for unconditional monomer design and state-of-the-art performance on various forms of motif scaffolding, including full-atom motif scaffolding and motif scaffolding without specifying motif segment spacing or relative sequence order.",
        "category": "Poster",
        "location": " San Diego"
    },
    {
        "id": 114,
        "title": "Can Biomolecular Structure Predictors Generalize to Alternative Conformations?",
        "authors": "Karson Chrispens, Henry van den Bedem, Stephanie Wankowicz, James Fraser",
        "abstract": "Proteins explore the conformational space around their native state to accomplish their function, so modeling the ensemble of accessible conformations is essential for understanding their behavior. Current structural models derived from macromolecular X-ray crystallography and single-particle cryogenic electron microscopy deposited in the Protein Data Bank are largely deposited as single states that fail to recognize the ensemble nature of proteins in experiments. Structure prediction models are trained on these single state structures, discarding cases where alternative conformations were manually built by an experimental modeler. Here, we apply steering of the Boltz-2 structure prediction model with synthetic density maps from manually modeled alternative conformations to explore the limitations of existing structure predictors. We find that sampling of alternative conformations is biased towards the single state structures in the training set despite the physical plausibility of the modeled alternative conformations, indicating limited ability to generalize in conformational space. To address this, we identify opportunities to overcome these limitations through augmenting training with alternative conformations and evaluating with experimental data.",
        "category": "Contributed talk",
        "location": " San Diego"
    },
    {
        "id": 115,
        "title": "Biophysical Priors Enhance Protein-Protein Binding DDG Prediction",
        "authors": "Antoine Maechler, Jonathan Feldman, Dianzhuo Wang, Eugene Shakhnovich",
        "abstract": "Predicting mutational effects on protein\u2013protein binding affinity ($\\Delta\\Delta G$) remains a challenging task: current models often generalize poorly due to limited and biased training data. We show that SKEMPI2, the dominant training and evaluation dataset in this field, is affected by a subtle and pervasive data leakage due to sequential and structural redundancy, leading to inflated estimates of performance across models. We introduce ProtBFF (\\underline{Prot}ein \\underline{B}iophysical \\underline{F}eature \\underline{F}ramework), a lightweight, encoder-agnostic module that injects five key biophysical features (interface, burial, dihedral, SASA, lDDT) into residue latent representations via cross-embedding attention. ProtBFF consistently improves predictive power and, with ProSST, achieves state-of-the-art performance on clustered SKEMPI2, rivaling far more specialized models. These results point to a simple, general recipe for protein property prediction: integrate biophysical priors with machine learning.",
        "category": "Poster",
        "location": " San Diego"
    },
    {
        "id": 119,
        "title": "TaxoFormer: Hierarchical Transformer for Predicting the Full Taxonomic Lineage of Protein Sequences",
        "authors": "Mohammad Parsa, Kathy Wei, Koosh Azimian",
        "abstract": "Predicting labels in massive, hierarchically structured output spaces is a core challenge in machine learning. In this work, we use the problem of predicting the full taxonomic lineage of a protein from its sequence as a case study for this challenge. We introduce TaxoFormer, an architecture whose primary contribution is a structured tokenization scheme that losslessly represents the entire NCBI phylogenetic tree\u2014a graph with over 1.3 million nodes\u2014using a compact vocabulary of just 15,000 tokens. By coupling a pre-trained ESM-2 model with an autoregressive decoder and training with a standard cross-entropy objective, we test the hypothesis that a simple generative objective is sufficient to learn complex, latent structure when the output space is explicitly modeled. We show that this approach is highly effective: on a dataset of 188 million proteins, the model not only achieves accurate lineage prediction but also implicitly learns a continuous, phylogenetically-structured latent space. This work provides a scalable, alignment-free method for taxonomic annotation and demonstrates that explicitly modeling the structure of a complex output space is a powerful mechanism for learning meaningful representations.",
        "category": "Contributed talk",
        "location": " San Diego"
    },
    {
        "id": 120,
        "title": "Structure-Aware Mapping of Disease-Relevant Missense Variation: A Case Study in Three Nuclear Pore Complex Genes",
        "authors": "Fatemeh Yekeh Yazdandoost, Mohammad Parsa",
        "abstract": "Missense variation in the nuclear pore complex (NPC) remains difficult to interpret because sequence change, structural context, and sparse clinical labels all interact in nontrivial ways. We study three functionally distinct nucleoporins GLE1, NUP214, and NUP62 and build a reproducible pipeline that binds variants to canonical UniProt coordinates, overlays AlphaFold2 per-residue confidence, and assigns domain/feature labels from UniProtKB/Pfam. Primary inferences rely strictly on curated ClinVar assertions, while a separate high-confidence pseudo-labeled cohort is created for sensitivity analyses using a guarded weak-supervision scheme: a centroid-cosine scorer over handcrafted sequence-structural features is ensembled with a positive-unlabeled classifier, and only variants passing conservative probability gates are promoted. Across genes, curated data reveal coherent structure-function signals: pathogenic substitutions concentrate in specific domains and structurally ordered regions, while the pseudo-labeled cohort preserves these trends under expanded sample size without entering into hypothesis tests. The result is a transparent workflow that cleanly separates ground truth from weak supervision, avoids leakage, and produces interpretable, domain-level effect estimates. We argue that this combination of principled labeling, structural context, and simple, auditable models offers a practical path for variant interpretation in nucleoporins and, more broadly, in proteins rich in intrinsically disordered and repeat-containing regions.",
        "category": "Poster",
        "location": " Copenhagen"
    },
    {
        "id": 125,
        "title": "FlexVASP-S: Flexible Steric-Aware 3D Geometric Framework for Explaining Protein Binding Specificity",
        "authors": "Yangying Liu, Houliang Zhou, Lifang He, Brian Chen",
        "abstract": "The design of selective ligands requires the discovery of binding site properties that distinguish targets from similar off-targets.  From a steric perspective, this problem is exacerbated by the intrinsic flexibility of proteins, which can hide variations in shape that could be exploited for selective design.  To address this problem, we propose FlexVASP-S, the first interpretable 3D geometic learning framework that identifies regions of hindrance in binding cavities that select for different ligands.  FlexVASP-S identifies these regions despite noisy conformational variations by using flexible structural representations and explainable AI techniques.  We tested FlexVASP-S on two superfamilies of proteins that have subfamilies with different ligand preferences, producing conformational variations of every protein with molecular dynamics simulations.  Even though substantial motion occurs, FlexVASP-S identified regions that accommodate ligands preferred by one subfamily and not by others, recapitulating established experimental findings.  It also accurately classified cavities with similar binding preferences. The code is publicly shared at \\url{https://github.com/LehighInfolab/FlexVASP-S}.",
        "category": "Poster",
        "location": " San Diego"
    },
    {
        "id": 129,
        "title": "Improving nanobody structure prediction with self-distillation",
        "authors": "Montader Ali, Matthew Greenig, Mateusz Jaskolowski, Mia Crnogaj, Eva Smorodina, Haowen Zhao, Victor Greiff, Pietro Sormanni",
        "abstract": "Nanobodies are increasingly attractive therapeutic and biotechnological molecules, yet accurate structure prediction of their highly variable H-CDR3 loops remains a central challenge for machine learning models. Here, we investigate whether nanobody-specific structure prediction can be improved through curated synthetic data strategies. We systematically evaluate different data augmentation regimes, including self-distillation from unlabelled VHH sequences. To ensure structural plausibility of synthetic training samples, we develop \\textbf{NanoKink}, the first sequence-based classifier of kinked versus extended H-CDR3 conformations, and apply stringent filtering criteria for non-canonical disulfide bond placement and conformational accuracy. On a curated benchmark enriched for challenging nanobody features, we show that, for a fixed training compute budget, a nanobody-specific model trained with filtered synthetic data significantly improves over baseline models and NanobodyBuilder2, achieving lower mean H-CDR3 RMSD and fewer structural violations, while remaining competitive with AlphaFold3 at approximately two orders of magnitude lower per-structure inference time. Our results highlight promising directions in synthetic data generation for nanobody structure modelling and provide a practical framework for optimisation of VHH structure prediction models.",
        "category": "Poster",
        "location": " San Diego"
    },
    {
        "id": 130,
        "title": "TangledFeatures: Robust Feature Selection in Highly Correlated Spaces",
        "authors": "Allen Sunny",
        "abstract": "Feature selection is a fundamental step in model development, shaping both predictive performance and interpretability. Yet, most widely used methods focus on predictive accuracy, and their performance degrades in the presence of correlated predictors. To address this gap, we introduce TangledFeatures, a framework for feature selection in correlated feature spaces. It identifies representative features from groups of entangled predictors, reducing redundancy while retaining explanatory power. The resulting feature subset can be directly applied in downstream models, offering a more interpretable and stable basis for analysis compared to traditional selection techniques. We demonstrate the effectiveness of TangledFeatures on Alanine Dipeptide, applying it to the prediction of backbone torsional angles \u03d5and \u03c8, and show that the selected features correspond to structurally meaningful intra-atomic distances that explain variation in these angles.",
        "category": "Poster",
        "location": " San Diego"
    },
    {
        "id": 132,
        "title": "GlycoGym: Benchmarking Glycan Property Prediction",
        "authors": "Roman Joeres, Daniel Bojar",
        "abstract": "Glycan property prediction is an increasingly popular area of machine learning research. Supervised learning approaches have shown promise in glycan modeling; however, the current literature is fragmented regarding datasets and standardized evaluation techniques, hampering progress in understanding these complex, branched carbohydrates, which play crucial roles in biological processes. To facilitate progress, we introduce GlycoGym, a comprehensive benchmark suite containing six biologically relevant supervised learning tasks spanning different domains of glycobiology: glycosylation linkage identification, tissue expression prediction, taxonomy classification, tandem mass spectrometry fragmentation prediction, lectin-glycan interaction modeling, and structural property estimation. We curate tasks into specific training, validation, and test splits using multi-class stratification to ensure that each task tests biologically relevant generalization that transfers to real-life glycan property prediction scenarios. We benchmark a diverse range of approaches to glycan representation learning, spanning fingerprint-based baselines, language models operating on IUPAC-condensed sequences, and graph neural networks explicitly designed for glycan topology, including SweetNet, GLAMOUR, and the recent GIFFLAR architecture. We find that specialized glycan encoders consistently outperform simple baselines for the more complex tasks. GlycoGym will help the machine learning community to focus their efforts on scientifically relevant glycan prediction problems and will be regularly updated through the GlycoGym Python package and on Zenodo. All data and code used to run these experiments are available on GitHub and Zenodo.",
        "category": "Poster",
        "location": " Copenhagen"
    },
    {
        "id": 134,
        "title": "Curriculum-Augmented GFlowNets For mRNA Sequence Generation",
        "authors": "Aya Laajil, Abduragim Shtanchaev, sajan mohammad, Eric Moulines, Salem Lahlou",
        "abstract": "Designing mRNA sequences is a major challenge in developing next-generation therapeutics, since it involves exploring a vast space of possible nucleotide combinations while optimizing sequence properties like stability, translation efficiency, and protein expression. While Generative Flow Networks are promising for this task, their training is hindered by sparse, long-horizon rewards and multi-objective trade-offs. We propose Curriculum\u2011Augmented GFlowNets (CAGFN), which integrate curriculum learning with multi\u2011objective GFlowNets to generate de novo mRNA sequences. CAGFN integrates a length\u2011based curriculum that progressively adapts the maximum sequence length guiding exploration from easier to harder subproblems.  We also provide a new mRNA design environment for GFlowNets which, given a target protein sequence and a combination of biological objectives, generates plausible mRNA candidates encoding the same protein. This provides a biologically motivated setting for applying and advancing GFlowNets in mRNA sequence design. On different mRNA tasks, CAGFN improves Pareto performance and biological plausibility, while maintaining sequence diversity. Moreover, CAGFN reaches higher-quality solutions faster than a GFlowNet trained with random sequence sampling (no curriculum), and enables generalization to out-of-distribution sequences.",
        "category": "Poster",
        "location": " San Diego"
    },
    {
        "id": 136,
        "title": "ProFam: an open protein family language model for functional protein design",
        "authors": "Jude Wells, Alex Hawkins-Hooker, Micha Livne, Weining Lin, David Miller, Christian Dallago, Nicola Bordin, Brooks Paige, Christine Orengo, Burkhard Rost, Michael Heinzinger",
        "abstract": "Protein language models have become essential tools for engineering novel functional proteins. Within this domain, family-conditioned models use homologous sequences to steer protein design and enhance zero-shot fitness prediction. To provide an open foundation for this modelling strategy, we introduce ProFam-1, a 251M-parameter autoregressive protein family language model (pfLM) that conditions on sets of homologous sequences to guide sequence scoring and generation. ProFam-1 achieves Spearman correlations of 0.47 for substitutions and 0.48 for indels in ProteinGym zero-shot fitness prediction, competitive with state-of-the-art models. For homology-guided generation, ProFam-1 generates diverse sequences with predicted structural similarity, while preserving residue conservation and covariance patterns. All of ProFam's training and inference pipelines, including a curated, large-scale training dataset ProFam-atlas, are released fully open source, lowering the barrier to future method development.",
        "category": "Contributed talk",
        "location": " Copenhagen"
    },
    {
        "id": 137,
        "title": "MomeDTA: Improving Generalizability in Drug-Target Affinity Prediction by Mixture of Multi-view Experts",
        "authors": "Qingyu Yang, Yue Teng, Jie Yang, Tao Zhang, Jiale Yu, Jie Zheng",
        "abstract": "Accurate prediction of drug-target affinity (DTA) plays an important role in targeted therapy and drug discovery by enabling efficient virtual screening. However, many computational methods for DTA prediction show poor accuracy on novel drug-target pairs and inconsistent performance across different datasets because they only focus on a single view. In this work, we present a novel method called MomeDTA, which utilizes mixture of multi-view expert models to adaptively fuse 1D, 2D and 3D information. Our method achieves state-of-the-art (SOTA) performance in multiple scenarios on different datasets, demonstrating that we successfully improve model generalizability in DTA prediction. All of our code is available at https://github.com/Yangqy-16/MomeDTA.",
        "category": "Poster",
        "location": " Copenhagen"
    },
    {
        "id": 139,
        "title": "Seek and You Shall Fold",
        "authors": "Nadav Bojan Sellam, Meital Bojan, Paul Schanda, Alexander Bronstein",
        "abstract": "Accurate protein structures are essential for understanding biological function, yet incorporating experimental data into protein generative models remains a major challenge.  Most predictors of experimental observables are non-differentiable, making them incompatible with gradient-based conditional sampling.  This is especially limiting in nuclear magnetic resonance, where rich data such as chemical shifts are hard to directly integrate into generative modeling.  We introduce a framework for non-differentiable guidance of protein generative models, coupling a continuous diffusion-based generator with any black-box objective via a tailored genetic algorithm.  We demonstrate its effectiveness across three modalities: pairwise distance constraints, nuclear Overhauser effect restraints, and for the first time chemical shifts.  These results establish chemical shift guided structure generation as feasible, expose key weaknesses in current predictors, and showcase a general strategy for incorporating diverse experimental signals.  Our work points toward automated, data-conditioned protein modeling beyond the limits of differentiability.",
        "category": "Poster",
        "location": " Copenhagen"
    },
    {
        "id": 141,
        "title": "On fine-tuning Boltz-2 for protein-protein affinity prediction",
        "authors": "James King, Lewis Cornwall, Joshua Meyers, Andrei Cristian Nica, James Day, Aaron Sim, Neil Dalchau, Lilly Wollman",
        "abstract": "Accurate prediction of protein\u2013protein binding affinities is vital for understand- ing molecular interactions and designing therapeutics. We adapt Boltz-2, a state- of-the-art structure-based protein\u2013ligand predictor, for protein\u2013protein affinity re- gression and evaluate it on two curated datasets: TCR3d and PPB-affinity. Despite high structural accuracy, Boltz-2-PPI underperforms relative to sequence-based baselines across both small- and large-scale regimes. However, combining Boltz embeddings with protein language model features yields complementary improve- ments, particularly for weaker sequence models. These results suggest that cur- rent structure-based representations are insufficient alone for affinity prediction but hold promise when integrated with sequence embeddings, motivating future multimodal strategies and broader training signals.",
        "category": "Poster",
        "location": " Copenhagen"
    },
    {
        "id": 142,
        "title": "Mechanistic Interpretability of Antibody Language Models Using SAEs",
        "authors": "Rebonto Haque, Ollie Turnbull, Anisha Parsan, Nithin Parsan, John Yang, Charlotte Deane",
        "abstract": "Sparse autoencoders (SAEs) are a mechanistic interpretability technique that have been used to provide insight into learned concepts within large protein language models. Here, we employ TopK and Ordered SAEs to investigate an autoregressive antibody language model, p-IgGen, and steer its generation. We show that TopK SAEs can reveal biologically meaningful latent features, but high feature\u2013concept correlation does not guarantee causal control over generation. In contrast, Ordered SAEs impose a hierarchical structure that reliably identifies steerable features, but at the expense of more complex and less interpretable activation patterns. These findings advance the mechanistic interpretability of domain-specific protein language models and suggest that, while TopK SAEs suffice for mapping latent features to concepts, Ordered SAEs are preferable when precise generative steering is required.",
        "category": "Poster",
        "location": " San Diego"
    }
]
